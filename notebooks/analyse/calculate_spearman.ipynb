{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score, f1_score,  precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gold_labels(dimension, task):\n",
    "    test_df = pd.read_csv(f\"../../data/processed/{dimension}/{task}_test.csv\")\n",
    "    with open(\"../../data/interim/labels.json\", \"r\") as json_input:\n",
    "        labels2ids = json.load(json_input)\n",
    "    test_df[\"labels\"] = test_df[\"labels\"].replace(labels2ids[task])\n",
    "    gold_labels = test_df[\"labels\"].to_list()\n",
    "    return gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spearmanr(gold, preds):\n",
    "    spearman_corr, pval = spearmanr(np.array(gold), np.array(preds))\n",
    "    return (spearman_corr, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: bert-base-cased | dimension: merged | task: propaganda | spearman: 1.0 | pval: 0.0\n",
      "model: bert-base-cased | dimension: merged | task: webis | spearman: 1.0 | pval: 0.0\n",
      "model: bert-base-cased | dimension: merged | task: pheme | spearman: 1.0 | pval: 0.0\n",
      "model: bert-base-cased | dimension: merged | task: basil | spearman: 1.0 | pval: 0.0\n",
      "model: bert-base-cased | dimension: merged | task: shadesoftruth | spearman: 0.3333333333333334 | pval: 0.6666666666666666\n",
      "model: bert-base-cased | dimension: merged | task: fingerprints | spearman: 1.0 | pval: 0.0\n",
      "model: bert-base-cased | dimension: merged | task: clickbait | spearman: 1.0 | pval: 0.0\n",
      "\n",
      "\n",
      "model: roberta-base | dimension: merged | task: propaganda | spearman: 1.0 | pval: 0.0\n",
      "model: roberta-base | dimension: merged | task: webis | spearman: 1.0 | pval: 0.0\n",
      "model: roberta-base | dimension: merged | task: pheme | spearman: 1.0 | pval: 0.0\n",
      "model: roberta-base | dimension: merged | task: basil | spearman: 1.0 | pval: 0.0\n",
      "model: roberta-base | dimension: merged | task: shadesoftruth | spearman: 1.0 | pval: 0.0\n",
      "model: roberta-base | dimension: merged | task: fingerprints | spearman: 1.0 | pval: 0.0\n",
      "model: roberta-base | dimension: merged | task: clickbait | spearman: 1.0 | pval: 0.0\n",
      "\n",
      "\n",
      "model: distilbert-base-cased | dimension: merged | task: propaganda | spearman: 1.0 | pval: 0.0\n",
      "model: distilbert-base-cased | dimension: merged | task: webis | spearman: 1.0 | pval: 0.0\n",
      "model: distilbert-base-cased | dimension: merged | task: pheme | spearman: 1.0 | pval: 0.0\n",
      "model: distilbert-base-cased | dimension: merged | task: basil | spearman: 1.0 | pval: 0.0\n",
      "model: distilbert-base-cased | dimension: merged | task: shadesoftruth | spearman: 1.0 | pval: 0.0\n",
      "model: distilbert-base-cased | dimension: merged | task: fingerprints | spearman: 1.0 | pval: 0.0\n",
      "model: distilbert-base-cased | dimension: merged | task: clickbait | spearman: 1.0 | pval: 0.0\n",
      "\n",
      "\n",
      "model: microsoft/deberta-base | dimension: merged | task: propaganda | spearman: 1.0 | pval: 0.0\n",
      "model: microsoft/deberta-base | dimension: merged | task: webis | spearman: 0.7999999999999999 | pval: 0.20000000000000007\n",
      "model: microsoft/deberta-base | dimension: merged | task: pheme | spearman: 1.0 | pval: 0.0\n",
      "model: microsoft/deberta-base | dimension: merged | task: basil | spearman: 1.0 | pval: 0.0\n",
      "model: microsoft/deberta-base | dimension: merged | task: shadesoftruth | spearman: 1.0 | pval: 0.0\n",
      "model: microsoft/deberta-base | dimension: merged | task: fingerprints | spearman: 1.0 | pval: 0.0\n",
      "model: microsoft/deberta-base | dimension: merged | task: clickbait | spearman: 1.0 | pval: 0.0\n",
      "\n",
      "\n",
      "model: facebook/FairBERTa | dimension: merged | task: propaganda | spearman: 1.0 | pval: 0.0\n",
      "model: facebook/FairBERTa | dimension: merged | task: webis | spearman: 1.0 | pval: 0.0\n",
      "model: facebook/FairBERTa | dimension: merged | task: pheme | spearman: 1.0 | pval: 0.0\n",
      "model: facebook/FairBERTa | dimension: merged | task: basil | spearman: 1.0 | pval: 0.0\n",
      "model: facebook/FairBERTa | dimension: merged | task: shadesoftruth | spearman: 1.0 | pval: 0.0\n",
      "model: facebook/FairBERTa | dimension: merged | task: fingerprints | spearman: 0.3333333333333334 | pval: 0.6666666666666666\n",
      "model: facebook/FairBERTa | dimension: merged | task: clickbait | spearman: 1.0 | pval: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_name = [\n",
    "    \"bert-base-cased\",\n",
    "    \"roberta-base\",\n",
    "    \"distilbert-base-cased\",\n",
    "    \"microsoft/deberta-base\",\n",
    "    \"facebook/FairBERTa\",\n",
    "]\n",
    "\n",
    "dimensions = [\n",
    "    \"merged\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    # \"buzzfeed\",\n",
    "    # \"politifact\",\n",
    "    # \"twittercovidq2\",\n",
    "    # \"clef22\",\n",
    "\n",
    "    \"propaganda\",\n",
    "    \"webis\",\n",
    "    \"pheme\",\n",
    "    \"basil\",\n",
    "    \"shadesoftruth\",\n",
    "    \"fingerprints\",\n",
    "    \"clickbait\",\n",
    "]\n",
    "\n",
    "\n",
    "for model_name in models_name:\n",
    "    for task in tasks:\n",
    "        tot_diff = []\n",
    "        for dimension in dimensions:\n",
    "\n",
    "            try:\n",
    "                vanilla_test_preds = list(np.load(f'../../data/interim/tot_predictions{os.sep}{model_name}{os.sep}{dimension}{os.sep}{task}{os.sep}unperturbed.npy'))\n",
    "                perturbed_test_preds = list(np.load(f'../../data/interim/tot_predictions{os.sep}{model_name}{os.sep}{dimension}{os.sep}{task}{os.sep}perturbed.npy'))\n",
    "\n",
    "                test_gold = load_gold_labels(dimension, task)\n",
    "\n",
    "            except:\n",
    "                print(f\"NO DATA FOR: {model_name} - {dimension} - {task}\")\n",
    "\n",
    "        van_acc = accuracy_score(test_gold, vanilla_test_preds)\n",
    "        pert_acc = accuracy_score(test_gold, perturbed_test_preds)\n",
    "        \n",
    "        van_f1 = f1_score(test_gold, vanilla_test_preds, average=\"macro\") \n",
    "        pert_f1 = f1_score(test_gold, perturbed_test_preds, average=\"macro\")\n",
    "\n",
    "        if len(set(test_gold)) > 2:\n",
    "            van_precision = precision_score(test_gold, vanilla_test_preds, average=\"weighted\")\n",
    "            pert_precision = precision_score(test_gold, perturbed_test_preds, average=\"weighted\")\n",
    "            van_recall = recall_score(test_gold, vanilla_test_preds, average=\"weighted\")\n",
    "            pert_recall = recall_score(test_gold, perturbed_test_preds, average=\"weighted\")\n",
    "\n",
    "        else:\n",
    "            van_precision = precision_score(test_gold, vanilla_test_preds)\n",
    "            pert_precision = precision_score(test_gold, perturbed_test_preds)\n",
    "            van_recall = recall_score(test_gold, vanilla_test_preds)\n",
    "            pert_recall = recall_score(test_gold, perturbed_test_preds)\n",
    "\n",
    "        vec_1 = [van_acc, van_f1, van_precision, van_recall]\n",
    "        vec_2 = [pert_acc, pert_f1, pert_precision, pert_recall]\n",
    "\n",
    "        sv, pval = calculate_spearmanr(vec_1, vec_2)\n",
    "        print(f\"model: {model_name} | dimension: {dimension} | task: {task} | spearman: {sv} | pval: {pval}\")\n",
    "    print(\"\\n\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
