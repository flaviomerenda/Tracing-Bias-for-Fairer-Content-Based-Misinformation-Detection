{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adapters import (\n",
    "    AutoAdapterModel\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/processed\"\n",
    "MODEL_PATH = \"../../models\"\n",
    "\n",
    "tunings = [\"finetuned\", \"fairtuned\"]\n",
    "dimension = \"merged\"\n",
    "tasks = [\"propaganda\", \"webis\", \"pheme\", \"basil\", \"shadesoftruth\", \"fingerprints\", \"clickbait\"]\n",
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_models_and_data = {}\n",
    "for task in tasks:\n",
    "    models_and_data = {}\n",
    "    for tuning in tunings:\n",
    "        if tuning == \"finetuned\":\n",
    "            model_folder_path = f\"../..{os.sep}models{os.sep}{model_name}{os.sep}vanilla{os.sep}{task}\"\n",
    "        else:\n",
    "            model_folder_path = f\"../..{os.sep}models{os.sep}{model_name}{os.sep}{dimension}{os.sep}{task}\"\n",
    "\n",
    "        CONFIG = {\n",
    "            \"task_name\": task,\n",
    "            \"model_name\": model_name,\n",
    "            \"model_path\": f\"{model_folder_path}{os.sep}{os.listdir(model_folder_path)[0]}{os.sep}{task}\",\n",
    "            \"max_length\": 128,\n",
    "        }\n",
    "\n",
    "        dataset_path = f\"{DATA_PATH}{os.sep}{dimension}\"\n",
    "\n",
    "        test_df = pd.read_csv(f\"{dataset_path}{os.sep}{CONFIG['task_name']}_test.csv\")\n",
    "        test_df = test_df.dropna()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "\n",
    "        model = AutoAdapterModel.from_pretrained(\n",
    "            CONFIG['model_name'],\n",
    "            output_attentions=True\n",
    "        )\n",
    "        model.load_adapter(CONFIG['model_path'])\n",
    "        model.set_active_adapters(task)\n",
    "        model.set_active_embeddings(\"default\")\n",
    "        models_and_data[tuning] = {\n",
    "            \"model\": model,\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"dataset\": test_df\n",
    "        }\n",
    "    task_models_and_data[task] = models_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(text, tokenizer, ref_token_id, sep_token_id, cls_token_id):\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_act(module, inp, out):\n",
    "  #global saved_act\n",
    "  #saved_act = out\n",
    "  return saved_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_path = \"../../heterogeneity/lists_for_perturbations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir(entity_path):\n",
    "    df_ent = pd.read_csv(f\"{entity_path}{file}\")\n",
    "    df_ent.columns = [\"original\", \"swap\"]\n",
    "    dfs.append(df_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_entities = pd.concat(dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: propaganda | Tuning: finetuned | Final target attribution avg: 0.13045565961742342 | Std: 0.1498988096778749 | Total data samples: 87\n",
      "Task: propaganda | Tuning: fairtuned | Final target attribution avg: 0.1740882033130756 | Std: 0.1890709638707351 | Total data samples: 87\n",
      "Task: webis | Tuning: finetuned | Final target attribution avg: 0.10821403801119417 | Std: 0.13558178200534354 | Total data samples: 244\n",
      "Task: webis | Tuning: fairtuned | Final target attribution avg: 0.10533005783055233 | Std: 0.14331763658236657 | Total data samples: 244\n",
      "Task: pheme | Tuning: finetuned | Final target attribution avg: 0.13319829309470294 | Std: 0.22310857851974136 | Total data samples: 57\n",
      "Task: pheme | Tuning: fairtuned | Final target attribution avg: 0.12209910530023847 | Std: 0.23202480415235183 | Total data samples: 57\n",
      "Task: basil | Tuning: finetuned | Final target attribution avg: 0.109724760017304 | Std: 0.12706068889636934 | Total data samples: 430\n",
      "Task: basil | Tuning: fairtuned | Final target attribution avg: 0.12976707791766529 | Std: 0.1502589850710165 | Total data samples: 430\n",
      "Task: shadesoftruth | Tuning: finetuned | Final target attribution avg: 0.1671533146094892 | Std: 0.2658737716342701 | Total data samples: 686\n",
      "Task: shadesoftruth | Tuning: fairtuned | Final target attribution avg: 0.13642261365607788 | Std: 0.21743459363906467 | Total data samples: 686\n",
      "Task: fingerprints | Tuning: finetuned | Final target attribution avg: 0.15085581466199188 | Std: 0.2096456022777046 | Total data samples: 1201\n",
      "Task: fingerprints | Tuning: fairtuned | Final target attribution avg: 0.10766170016738832 | Std: 0.15093016401374293 | Total data samples: 1201\n",
      "Task: clickbait | Tuning: finetuned | Final target attribution avg: 0.26012729362670745 | Std: 0.2299360944276102 | Total data samples: 767\n",
      "Task: clickbait | Tuning: fairtuned | Final target attribution avg: 0.2129033718503367 | Std: 0.21908967777220967 | Total data samples: 767\n",
      "Final fine target attr: 0.15138988194840186 | Final std: 0.04846487268479332\n",
      "Final fair target attr: 0.14118173286219066 | Final std: 0.03616007018187026\n"
     ]
    }
   ],
   "source": [
    "tot_final_target_avg_fine = []\n",
    "tot_final_target_avg_fair = []\n",
    "for task, models_and_data in task_models_and_data.items():\n",
    "    for tuning, data in models_and_data.items():\n",
    "        \n",
    "        model = data[\"model\"]\n",
    "        tokenizer = data[\"tokenizer\"]\n",
    "        df = data[\"dataset\"]\n",
    "\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        model.zero_grad()\n",
    "\n",
    "        def predict(inputs):\n",
    "            return model(inputs)[0]\n",
    "\n",
    "        def custom_forward(inputs):\n",
    "            preds = predict(inputs)\n",
    "            return torch.softmax(preds, dim = 1)[:, 0] # for negative attribution, torch.softmax(preds, dim = 1)[:, 1] <- for positive attribution\n",
    "        \n",
    "        label2id = model.config.prediction_heads[task][\"label2id\"]\n",
    "        id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "        lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)\n",
    "\n",
    "        sents_len = []\n",
    "        all_target_att = []\n",
    "        entity_to_sum = 0\n",
    "        for sample in df.to_dict(\"records\"):\n",
    "            if sample[\"entity\"]:\n",
    "                entity_to_sum +=1\n",
    "                text = sample[\"perturbed_text\"]\n",
    "                label = sample[\"labels\"]\n",
    "                if sample[\"entity\"] not in target_entities['original'].tolist():\n",
    "                    continue\n",
    "                if sample[\"entity\"] == \"US\":\n",
    "                    sample[\"entity\"] = \"America\"\n",
    "                entity = target_entities.loc[target_entities['original'] == sample[\"entity\"], 'swap'].iloc[0]\n",
    "\n",
    "                input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, tokenizer, ref_token_id, sep_token_id, cls_token_id)\n",
    "                token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "                position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "                attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "                indices = input_ids[0].detach().tolist()\n",
    "                all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "                sents_len.append(len(all_tokens))\n",
    "\n",
    "                pred = predict(input_ids)\n",
    "\n",
    "                attributions, delta = lig.attribute(\n",
    "                    inputs=input_ids,\n",
    "                    baselines=ref_input_ids,\n",
    "                    n_steps=10,\n",
    "                    internal_batch_size=3,\n",
    "                    return_convergence_delta=True\n",
    "                )\n",
    "                \n",
    "                score = predict(input_ids)\n",
    "\n",
    "                attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "                tot_target_att = []\n",
    "                for idx in range(len(input_ids[0])):\n",
    "                    if tokenizer.decode(input_ids[0][idx]) in entity.split():\n",
    "                        tot_target_att.append(attributions_sum[idx])\n",
    "                target_att = float(abs(sum(tot_target_att)))\n",
    "                all_target_att.append(target_att)\n",
    "\n",
    "        final_target_avg = np.mean(all_target_att)\n",
    "        std = np.std(all_target_att)\n",
    "        print(f\"Task: {task} | Tuning: {tuning} | Final target attribution avg: {final_target_avg} | Std: {std} | Total data samples: {entity_to_sum}\")\n",
    "        if tuning == \"finetuned\":\n",
    "            tot_final_target_avg_fine.append(final_target_avg)\n",
    "        else:\n",
    "            tot_final_target_avg_fair.append(final_target_avg)\n",
    "\n",
    "print(f\"Final fine target attr: {np.mean(tot_final_target_avg_fine)} | Final std: {np.std(tot_final_target_avg_fine)}\")\n",
    "print(f\"Final fair target attr: {np.mean(tot_final_target_avg_fair)} | Final std: {np.std(tot_final_target_avg_fair)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misinfo_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
