{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/perturber\").to(device=\"cuda\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/perturber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = \"gender\"\n",
    "ENTITY_TYPE = [\"PERSON\", \"ORG\"]\n",
    "TARGET = \"woman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = \"../../data/raw\"\n",
    "PROCESSED_PATH = \"../../data/processed\"\n",
    "SEP = \"<PERT_SEP>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_entities = pd.read_csv(\"../../heterogeneity/lists_for_perturbations/names_swaps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NamedEntity</th>\n",
       "      <th>GenderSwapEntity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Bush</td>\n",
       "      <td>Sarah Palin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Marine Le-Pen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>Theresa May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jesus Christ</td>\n",
       "      <td>Alexandria Ocasio-Cortez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Angela Merkel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adolf Hitler</td>\n",
       "      <td>Jacinda Ardern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ronald Reagan</td>\n",
       "      <td>Margaret Thatcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>Paula Dobrainsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mitt Romney</td>\n",
       "      <td>Nirmala Sitharaman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>John McCain</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bashar al-Assad</td>\n",
       "      <td>Sanna Marin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Francis Fukuyama</td>\n",
       "      <td>Xiomara Castro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>John F. Kennedy</td>\n",
       "      <td>Ngozi Okonjo-Iweala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>Halimah Yacob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ron Paul</td>\n",
       "      <td>Michelle Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Robert Parry</td>\n",
       "      <td>Dilma Rousseff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Benjamin Netanyahu</td>\n",
       "      <td>Roza Otunbayeva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Robert Faurisson</td>\n",
       "      <td>Michelle Bachelet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Frank Gaffney</td>\n",
       "      <td>Giorgia Meloni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>Pratibha Patil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ditlieb Felderer</td>\n",
       "      <td>Sherry Rehman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lindsay Graham</td>\n",
       "      <td>Yolanda Diaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>John Kerry</td>\n",
       "      <td>Roberta Metsola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Cristina Fernandez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Najla Bouden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Tucker Carson</td>\n",
       "      <td>Oprah Winfrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Franklin Roosevelt</td>\n",
       "      <td>Paula Ingabire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Richard Nixon</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Recep Erdogan</td>\n",
       "      <td>Lauren Boebert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NamedEntity          GenderSwapEntity\n",
       "0         Barack Obama           Hillary Clinton\n",
       "1          George Bush               Sarah Palin\n",
       "2         Donald Trump             Marine Le-Pen\n",
       "3         Bill Clinton               Theresa May\n",
       "4         Jesus Christ  Alexandria Ocasio-Cortez\n",
       "5       Vladimir Putin             Angela Merkel\n",
       "6         Adolf Hitler           Jacinda Ardern \n",
       "7        Ronald Reagan         Margaret Thatcher\n",
       "8             Ted Cruz          Paula Dobrainsky\n",
       "9          Mitt Romney        Nirmala Sitharaman\n",
       "10         John McCain          Elizabeth Warren\n",
       "11     Bashar al-Assad               Sanna Marin\n",
       "12    Francis Fukuyama            Xiomara Castro\n",
       "13     John F. Kennedy       Ngozi Okonjo-Iweala\n",
       "14       Boris Johnson             Halimah Yacob\n",
       "15            Ron Paul            Michelle Obama\n",
       "16        Robert Parry            Dilma Rousseff\n",
       "17  Benjamin Netanyahu           Roza Otunbayeva\n",
       "18    Robert Faurisson         Michelle Bachelet\n",
       "19       Frank Gaffney            Giorgia Meloni\n",
       "20    Thomas Jefferson            Pratibha Patil\n",
       "21    Ditlieb Felderer             Sherry Rehman\n",
       "22      Lindsay Graham              Yolanda Diaz\n",
       "23          John Kerry           Roberta Metsola\n",
       "24           Joe Biden        Cristina Fernandez\n",
       "25      Bernie Sanders              Najla Bouden\n",
       "26       Tucker Carson             Oprah Winfrey\n",
       "27  Franklin Roosevelt            Paula Ingabire\n",
       "28       Richard Nixon         Christine Lagarde\n",
       "29       Recep Erdogan            Lauren Boebert"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_to_entity =  pd.read_csv(\"../../heterogeneity/lists_for_perturbations/twitter_user_to_entity.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>UserSwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BarackObama</td>\n",
       "      <td>Barack Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@TheBushCenter</td>\n",
       "      <td>George Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td>Donald Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BillClinton</td>\n",
       "      <td>Bill Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@KremlinRussia_E</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@RonaldReagan</td>\n",
       "      <td>Ronald Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@SenTedCruz</td>\n",
       "      <td>Ted Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@MittRomney</td>\n",
       "      <td>Mitt Romney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@SenJohnMcCain</td>\n",
       "      <td>John McCain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@FukuyamaFrancis</td>\n",
       "      <td>Francis Fukuyama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@BorisJohnson</td>\n",
       "      <td>Boris Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@RonPaul</td>\n",
       "      <td>Ron Paul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@netanyahu</td>\n",
       "      <td>Benjamin Netanyahu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@frankgaffney</td>\n",
       "      <td>Frank Gaffney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@LindseyGrahamSC</td>\n",
       "      <td>Lindsay Graham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@JohnKerry</td>\n",
       "      <td>John Kerry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@JoeBiden</td>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@BernieSanders</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@rterdogan_ar</td>\n",
       "      <td>Recep Erdogan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                User            UserSwap\n",
       "0       @BarackObama        Barack Obama\n",
       "1     @TheBushCenter         George Bush\n",
       "2   @realDonaldTrump        Donald Trump\n",
       "3       @BillClinton        Bill Clinton\n",
       "5   @KremlinRussia_E      Vladimir Putin\n",
       "7      @RonaldReagan       Ronald Reagan\n",
       "8        @SenTedCruz            Ted Cruz\n",
       "9        @MittRomney         Mitt Romney\n",
       "10    @SenJohnMcCain         John McCain\n",
       "12  @FukuyamaFrancis    Francis Fukuyama\n",
       "14     @BorisJohnson       Boris Johnson\n",
       "15          @RonPaul            Ron Paul\n",
       "17        @netanyahu  Benjamin Netanyahu\n",
       "19     @frankgaffney       Frank Gaffney\n",
       "22  @LindseyGrahamSC      Lindsay Graham\n",
       "23        @JohnKerry          John Kerry\n",
       "24         @JoeBiden           Joe Biden\n",
       "25    @BernieSanders      Bernie Sanders\n",
       "29     @rterdogan_ar       Recep Erdogan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_to_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entity(text, entity, df, search_column, return_column):\n",
    "    # Check if the substring is present in the search column\n",
    "    mask = df[search_column].str.contains(entity)\n",
    "\n",
    "    # If a match is found, return the corresponding value from the return column\n",
    "    if mask.any():\n",
    "        swap_entity = df.loc[mask, return_column].iloc[0]\n",
    "        regex = f\"([A-Z]([a-z]+|\\.)\\s*)*{entity.split(' ')[-1]}\"\n",
    "        text = re.sub(r''+regex, swap_entity, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text_entity_to_substitute = (text, None)\n",
    "    tw_users = twitter_to_entity[\"User\"].to_list()\n",
    "    for entity in tw_users:\n",
    "        if entity in text:\n",
    "            text = replace_entity(text, entity, twitter_to_entity, \"User\", \"UserSwap\")\n",
    "    # Create Doc object\n",
    "    doc2 = nlp(text)\n",
    "    # print([(ent.text, ent.label_) for ent in doc2.ents])\n",
    "    # Identify the entities\n",
    "    entities = [ent.text for ent in doc2.ents if ent.label_ in ENTITY_TYPE]\n",
    "    # print(\"entities: \", entities)\n",
    "    if entities:\n",
    "        matched_entities = []\n",
    "        for entity in entities:\n",
    "            if any(entity in token for token in target_entities['NamedEntity'].to_list()):\n",
    "                is_substring_present = target_entities['NamedEntity'].str.contains(entity)\n",
    "                entity_to_substitute = target_entities.loc[is_substring_present, 'NamedEntity'].values[0]\n",
    "                if entity != entity_to_substitute:\n",
    "                    text = text.replace(entity, entity_to_substitute)\n",
    "                matched_entities.append((text, entity_to_substitute))\n",
    "        if matched_entities:\n",
    "            # print(\"matched_ entities: \", matched_entities[0][1])\n",
    "            text_entity_to_substitute = matched_entities[0]\n",
    "\n",
    "    return text_entity_to_substitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = []\n",
    "for path in os.walk(RAW_PATH):\n",
    "    for file in path[2]:\n",
    "        if file.endswith(\"test.csv\") or file.endswith(\"train.csv\"):\n",
    "            data_paths.append(f\"{path[0]}{os.sep}{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(sents, batch_size):\n",
    "    for i in range(0, len(sents), batch_size):\n",
    "        yield sents[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists file: ../data/processed/gender/fingerprints_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/fingerprints_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/clef22_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/clef22_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/twittercovidq2_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/basil_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/clickbait_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/basil_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/politifact_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/webis_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/buzzfeed_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/twittercovidq2_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/propaganda_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/buzzfeed_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/propaganda_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/pheme_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/pheme_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/webis_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/clickbait_train.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/politifact_test.csv. Skip.\n",
      "Already exists file: ../data/processed/gender/shadesoftruth_test.csv. Skip.\n",
      "Processing ../data/raw/shadesoftruth copy/shadesoftruth_train.csv\n",
      "Truncating texts...\n",
      "...texts truncated!\n",
      "preprocessing text and extracting entities...\n",
      "...text preprocessed and entities extracted!\n",
      "Perturbating texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6400/6400 [26:32<00:00,  4.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...texts perturbated!\n",
      "../data/processed/gender/shadesoftruth_train.csv created\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in data_paths:\n",
    "\n",
    "    path2check = f'{PROCESSED_PATH}{os.sep}{DIMENSION}{os.sep}{path.split(\"/\")[-1]}'\n",
    "    if os.path.exists(path2check):\n",
    "        print(f\"Already exists file: {path2check}. Skip.\")\n",
    "        continue\n",
    "\n",
    "    data = pd.read_csv(path).dropna()\n",
    "\n",
    "    print(f\"Processing {path}\")\n",
    "\n",
    "    print(\"Truncating texts...\")\n",
    "    data['text'] = data.apply(\n",
    "    lambda row: tokenizer.batch_decode(\n",
    "        tokenizer(\n",
    "            row.text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "        )[\"input_ids\"],\n",
    "    skip_special_tokens=True\n",
    "    )[0],\n",
    "    axis = 1\n",
    "    )\n",
    "    print(\"...texts truncated!\")\n",
    "\n",
    "    print(\"preprocessing text and extracting entities...\")\n",
    "    preprocessed_text = []\n",
    "    entities = []\n",
    "    for row in data[\"text\"].to_list():\n",
    "        text, entity = preprocess_text(row)\n",
    "        preprocessed_text.append(text)\n",
    "        entities.append(entity)\n",
    "    data[\"preprocessed_text\"] = preprocessed_text\n",
    "    data[\"entity\"] = entities\n",
    "    print(\"...text preprocessed and entities extracted!\")\n",
    "\n",
    "    data['perturber_input'] = data.apply(\n",
    "        lambda row: f\"{row.entity.split(' ')[0]}, {TARGET} {SEP} {row.preprocessed_text}\" \n",
    "        if row.entity else row.preprocessed_text, axis=1\n",
    "    )\n",
    "\n",
    "    print(\"Perturbating texts...\")\n",
    "    perturber_input = data[\"perturber_input\"].to_list()\n",
    "    entities = data[\"entity\"].to_list()\n",
    "    with torch.no_grad():\n",
    "        perturbed_texts = []\n",
    "        for input, entity in zip(tqdm(perturber_input, total=len(perturber_input)), entities):\n",
    "            if entity:\n",
    "                tokenized_batch = tokenizer(\n",
    "                    input,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=128\n",
    "                )\n",
    "                outputs = model.generate(\n",
    "                    tokenized_batch[\"input_ids\"].to(device=\"cuda\"),\n",
    "                    max_length=128,\n",
    "                )\n",
    "                perturbed_texts.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "            else:\n",
    "                perturbed_texts.append(input)\n",
    "\n",
    "    perturbated_substituted_entities = []\n",
    "    for text, entity in zip(perturbed_texts, entities):\n",
    "        if entity:\n",
    "            perturbated_substituted_entities.append(replace_entity(text, entity, target_entities, \"NamedEntity\", \"GenderSwapEntity\"))\n",
    "        else:\n",
    "            perturbated_substituted_entities.append(text)\n",
    "    data['perturbed_text'] = perturbated_substituted_entities\n",
    "    data = data[[\"text\", \"perturbed_text\", \"entity\", \"labels\"]]\n",
    "\n",
    "    print(\"...texts perturbated!\")\n",
    "\n",
    "    if not os.path.exists(f\"{PROCESSED_PATH}{os.sep}{DIMENSION}\"):\n",
    "        os.mkdir(f\"{PROCESSED_PATH}{os.sep}{DIMENSION}\")\n",
    "\n",
    "    data_path = f\"{PROCESSED_PATH}{os.sep}{DIMENSION}{os.sep}{path.split('/')[-1]}\"\n",
    "    data.to_csv(data_path, index=False, header=True, encoding=\"utf-8\")\n",
    "    print(f\"{data_path} created\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misinfo_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
